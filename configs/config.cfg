[general]
use_gpu=True
seed=123
num_worker=4

[data]
train_size=0.8

[model]
input_len=32
vocab_size=36
hidden_dim=256
n_attn_heads=8
n_layers=3
dropout=0.1
norm_first=True

[training]
lr=0.001
n_epochs=20
train_bsz=64
val_bsz=64
model_dir=checkpoints

[data_path]
raw_dataset=data\raw\dataset.txt
train_dataset=data\processed\train_dataset.txt
test_dataset=data\processed\test_dataset.txt
val_dataset=data\processed\val_dataset.txt
vocab=data\resources\vocab.json
model_ckpt=checkpoints\seq2seq_256_8_3.pt